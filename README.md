<p align="center">
  <img src="hydra-logo-purple-1024.png" alt="Hydra Logo" width="180"/>
</p>
# Hydra: Structured Cross-Source Enhanced LLM Reasoning

ðŸ”— [Website](https://stevetantan.github.io/Hydra/)  
ðŸ“„ [Paper (PDF)](https://arxiv.org/pdf/2505.17464)  
## News!
Our paper has been accepted for publication at EMNLP 2025 Main Conference! 

## How to cite
If you are interested or inspired by this work, you can cite us by:
```sh
@misc{tan2025hydra,
      title={Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning}, 
      author={Xingyu Tan and Xiaoyang Wang and Qing Liu and Xiwei Xu and Xin Yuan and Liming Zhu and Wenjie Zhang},
      year={2025},
      eprint={2505.17464},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2505.17464}, 
}
```

## Code Documentation 
Hydra unifies structured knowledge graphs, Wikipedia documents, and live web search so that large language models can **reason over verified multiâ€‘source evidence**. 

---

## Directory layout

```text
Hydra/
â”œâ”€â”€ answer/                 evaluation helpers and scoring scripts
â”œâ”€â”€ data/                   benchmark datasets (CWQ, AdvHotpotQA, QALD10-en, SimpleQA, WebQSP, Webquestions, Zeroshot RE)
â”œâ”€â”€ Freebase/               Freebase environment setting. See Freebase/README.md for details.
â”œâ”€â”€ freebase_subgraph/      Freebase subgraph KG
â”œâ”€â”€ Hydra_run/              main source folder â€“ run code from here
â”‚   â”œâ”€â”€ hydra_main.py       entry point
â”‚   â”œâ”€â”€ cot_prompt_list.py  chainâ€‘ofâ€‘thought prompts
â”‚   â”œâ”€â”€ freebase_func.py    Freebase SPARQL helpers
â”‚   â”œâ”€â”€ wiki_client.py      WikiKG client helpers
â”‚   â”œâ”€â”€ subgraph_helper.py  extra graph helpers
â”‚   â”œâ”€â”€ subgraph_utilts.py  subgraph construction utilities
â”‚   â”œâ”€â”€ detected_kgsub.py   KG maximum subgraph detection
â”‚   â”œâ”€â”€ resp_process.py     response postâ€‘processing
â”‚   â”œâ”€â”€ utilts.py           shared utilities
â”‚   â””â”€â”€ utilts2.py          extra utilities
â”œâ”€â”€ online_search/          live web search and documents caching
â”œâ”€â”€ wiki_subgraph/          Wiki subgraph KG
â”œâ”€â”€ Wikidata/               Wikidata environment setting. See Wikidata/README.md for details.
â”œâ”€â”€ requirements.txt        Python dependencies
â””â”€â”€ README.md               this file
```

---


## Get started
Before running Hydra, please ensure you have successfully installed **Freebase**, and **Wikidata** on your local machine. The comprehensive installation instructions and necessary configuration details can be found in the `/Freebase/README.md` and `/Wikidata/README.md`.

Once Wikidata is set up, copy the `server_urls.txt` files from the Wikidata directory into the Hydra_run folder.

You must use your own API in the `run_LLM` function of `utilts.py` for the APIs, and your own SerpAPI in `utilts2.py` for online search.

To set up the environment, install the required dependencies using:

```bash
cd Hydra
```

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```





---

## Commandâ€‘line interface

`hydra_main.py` exposes the options defined in `build_parser`.

```bash
cd Hydra/Hydra_run

python hydra_main.py \
  webqsp \                 # positional: dataset name prefix
  --depth 3 \              # maximum hop depth
  --allr \                 # Using Hydra instead of Hydra-E
  --model llama70b \       # LLM backend

```

### Positional argument

| Argument    | Meaning                                                                                                                             |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| `file_name` | Dataset prefix. Supported values include `CWQ`, `hotpot` (AdvHotpotQA), `qald`, `simpleqa`, `webqsp`, `webquestions`, `zeroshotre`. |

### Main options

| Flag                                          | Description                                                                                  | Default    |
| --------------------------------------------- | -------------------------------------------------------------------------------------------- | ---------- |
| `--allsource`                                 | Enable all sources in every expansion step                                                   | off        |
| `--allr`                                      | (Hydra) rather than a single relation (Hydraâ€‘E)                 | off        |
| `--incomplete`                                | Work with an incomplete KG split                                                             | off        |
| `--ratio {100,80,50,30}`                      | When `--incomplete` is on, sample the KG at the given percentage                             | `100`      |
| `--no-summary`                                | Disable summary generation                                                                   | on         |
| `--no-freebase`                               | Disable Freebase KG                                                                          | on         |
| `--no-wikikg`                                 | Disable WikiKG                                                                               | on         |
| `--no-web`                                    | Disable web search                                                                           | on         |
| `--no-wikidocu`                               | Disable retrieval from Wikipedia documents                                                   | on         |
| `--model {gpt3,gpt4,llama,deepseek,llama70b}` | LLM backend.<be> `gpt3`  = GPT-3.5-Turbo,   `gpt4`  = GPT-4-Turbo, `llama` = Llamaâ€‘3.1â€‘8B, `deepseek` = DeepSeekâ€‘v3, `llama70b` = Llamaâ€‘3.1â€‘70B | `llama70b` |
| `--depth {1,2,3,4}`                           | Maximum search depth                                                                         | `3`        |

> Modules remain active unless explicitly disabled with a `--noâ€‘*` flag.

---

## Examples

Run Hydra with all sources and a fourâ€‘hop search on CWQ:

```bash
python hydra_main.py CWQ --allsource --depth 4 --model gpt3
```

Run an ablation without web evidence and using an incomplete KG sampled at 50Â percent:

```bash
python hydra_main.py webqsp \
  --no-web \
  --incomplete --ratio 50 \
  --depth 3
```

Outputs are stored under `/Hydra/answer/` and include logs, intermediate paths, and final predictions.

### Subgraph Loading:
Hydra will load the subgraph at maximum depths first from KG as part of the database preparation. The loading time depends on the environment setup and memory allocated for the Freebase and Wikidata server.
You can run the subgraph loading individually:
```bash
python detected_kgsub.py webqsp # positional: dataset name prefix
```

### KG usage:
Hydra utilze the Freebase and Wikidata KG. For more details about installation, please take a look at the Freebase and Wikidata folders.

---

## Evaluation

Accuracy is computed with the answer in `Hydra/answer/`. The positional argument is the same as hydra_main.py

```bash
python check_answer.py \
  webqsp \                 # positional: dataset name prefix
  --depth 3 \              # maximum hop depth
  --allr \                 # Using Hydra instead of Hydra-E
  --model llama70b \       # LLM backend
```


## Notes
- Ensure that the dataset files and model configurations are correctly set up before running the scripts.
- Use appropriate depth values based on the complexity of the dataset and required accuracy.

---


## Claims
This project uses the Apache 2.0 protocol. The project assumes no legal responsibility for any of the model's output and will not be held liable for any damages that may result from the use of the resources and output.




